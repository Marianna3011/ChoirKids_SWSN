{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da39e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OGB available: False\n",
      "Raw data dir exists: False\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: ogb and torch (used if CSVs are not present)\n",
    "try:\n",
    "    from ogb.nodeproppred import NodePropPredDataset\n",
    "    _OGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    _OGB_AVAILABLE = False\n",
    "\n",
    "DATA_RAW = Path('data/raw')\n",
    "DATA_PROCESSED = Path('data/processed')\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('OGB available:', _OGB_AVAILABLE)\n",
    "print('Raw data dir exists:', DATA_RAW.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd9c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_csv(data_dir=DATA_RAW):\n",
    "    # Expected CSV files: node-feat.csv, node-label.csv, edge.csv\n",
    "    feat_path = data_dir / 'node-feat.csv'\n",
    "    label_path = data_dir / 'node-label.csv'\n",
    "    edge_path = data_dir / 'edge.csv'\n",
    "\n",
    "    if not feat_path.exists() or not label_path.exists() or not edge_path.exists():\n",
    "        raise FileNotFoundError('One or more expected CSVs are missing in ' + str(data_dir))\n",
    "\n",
    "    node_feat = pd.read_csv(feat_path, header=None)\n",
    "    node_label = pd.read_csv(label_path, header=None)\n",
    "    edge_index = pd.read_csv(edge_path, header=None)\n",
    "\n",
    "    # Ensure integer node indices\n",
    "    edge_index = edge_index.astype(int)\n",
    "    edge_index.columns = ['src','dst']\n",
    "\n",
    "    # Remove self-loops\n",
    "    edge_index = edge_index[edge_index['src'] != edge_index['dst']]\n",
    "\n",
    "    # Drop duplicate undirected edges (optional: treat as undirected)\n",
    "    # Create canonical ordering for undirected deduplication\n",
    "    edge_min = edge_index[['src','dst']].min(axis=1)\n",
    "    edge_max = edge_index[['src','dst']].max(axis=1)\n",
    "    dedup = pd.DataFrame({'u': edge_min, 'v': edge_max})\n",
    "    dedup = dedup.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Rebuild edge_index as directed edges from dedup (both directions)\n",
    "    edges_u = pd.DataFrame({'src': dedup['u'], 'dst': dedup['v']})\n",
    "    edges_v = pd.DataFrame({'src': dedup['v'], 'dst': dedup['u']})\n",
    "    cleaned_edges = pd.concat([edges_u, edges_v], ignore_index=True)\n",
    "\n",
    "    # Basic stats\n",
    "    num_nodes = node_feat.shape[0]\n",
    "    num_edges = cleaned_edges.shape[0]\n",
    "\n",
    "    print(f'Nodes: {num_nodes}, Edges (directed, cleaned): {num_edges}')\n",
    "\n",
    "    # Compute degrees\n",
    "    degrees = np.zeros(num_nodes, dtype=int)\n",
    "    for src, dst in cleaned_edges.values:\n",
    "        if 0 <= src < num_nodes:\n",
    "            degrees[int(src)] += 1\n",
    "    # Save processed artifacts\n",
    "    node_feat.to_parquet(DATA_PROCESSED / 'node-feat.parquet', index=False)\n",
    "    node_label.to_parquet(DATA_PROCESSED / 'node-label.parquet', index=False)\n",
    "    cleaned_edges.to_csv(DATA_PROCESSED / 'edge-cleaned.csv', index=False)\n",
    "    np.save(DATA_PROCESSED / 'degrees.npy', degrees)\n",
    "\n",
    "    return node_feat, node_label, cleaned_edges, degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04f07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_ogb(name='ogbn-products', save_processed=True):\n",
    "    if not _OGB_AVAILABLE:\n",
    "        raise RuntimeError('OGB is not installed in this environment')\n",
    "    ds = NodePropPredDataset(name=name)\n",
    "    graph = ds.graph\n",
    "    node_feat = pd.DataFrame(graph['node_feat'])\n",
    "    node_label = pd.DataFrame(graph['node_label'])\n",
    "    edge_index = pd.DataFrame(graph['edge_index'].T, columns=['src','dst'])\n",
    "    # Use same cleaning as CSV path\n",
    "    edge_index = edge_index.astype(int)\n",
    "    edge_index = edge_index[edge_index['src'] != edge_index['dst']]\n",
    "    edge_min = edge_index[['src','dst']].min(axis=1)\n",
    "    edge_max = edge_index[['src','dst']].max(axis=1)\n",
    "    dedup = pd.DataFrame({'u': edge_min, 'v': edge_max}).drop_duplicates().reset_index(drop=True)\n",
    "    edges_u = pd.DataFrame({'src': dedup['u'], 'dst': dedup['v']})\n",
    "    edges_v = pd.DataFrame({'src': dedup['v'], 'dst': dedup['u']})\n",
    "    cleaned_edges = pd.concat([edges_u, edges_v], ignore_index=True)\n",
    "    num_nodes = node_feat.shape[0]\n",
    "    degrees = np.zeros(num_nodes, dtype=int)\n",
    "    for src, dst in cleaned_edges.values:\n",
    "        degrees[int(src)] += 1\n",
    "    if save_processed:\n",
    "        node_feat.to_parquet(DATA_PROCESSED / 'node-feat.parquet', index=False)\n",
    "        node_label.to_parquet(DATA_PROCESSED / 'node-label.parquet', index=False)\n",
    "        cleaned_edges.to_csv(DATA_PROCESSED / 'edge-cleaned.csv', index=False)\n",
    "        np.save(DATA_PROCESSED / 'degrees.npy', degrees)\n",
    "    print(f'Loaded {name}: nodes={num_nodes}, cleaned edges={cleaned_edges.shape[0]}')\n",
    "    return node_feat, node_label, cleaned_edges, degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ce3dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load failed: No CSVs in data/raw/ and OGB not available\n"
     ]
    }
   ],
   "source": [
    "# Try CSVs first, otherwise try OGB\n",
    "try:\n",
    "    if DATA_RAW.exists() and any(DATA_RAW.glob('*.csv')):\n",
    "        feat, label, edges, degrees = load_from_csv(DATA_RAW)\n",
    "    elif _OGB_AVAILABLE:\n",
    "        feat, label, edges, degrees = load_from_ogb()\n",
    "    else:\n",
    "        raise FileNotFoundError('No CSVs in data/raw/ and OGB not available')\n",
    "except Exception as e:\n",
    "    print('Load failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcbffee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `degrees` array available. Run the load cell first.\n"
     ]
    }
   ],
   "source": [
    "# Quick EDA: degree stats and histogram\n",
    "try:\n",
    "    print('Degree mean:', degrees.mean())\n",
    "    print('Degree median:', np.median(degrees))\n",
    "    print('Degree min/max:', degrees.min(), degrees.max())\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(degrees, bins=100, log_scale=(False, True))\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Count (log)')\n",
    "    plt.title('Degree distribution (processed)')\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print('No `degrees` array available. Run the load cell first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a8335",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Use `data/processed/node-feat.parquet`, `node-label.parquet`, and `edge-cleaned.csv` for model training or further feature engineering.\n",
    "- Consider converting the cleaned edges to a sparse adjacency matrix or PyTorch Geometric format for faster GNN pipelines.\n",
    "- If you want, I can update `uv_project/requirements.txt` to include `ogb`, `pyarrow` (for parquet), and plotting libs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
