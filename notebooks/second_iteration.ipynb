{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879ef3a2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fa4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad5996",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Loading the ogbn-products dataset from cache (already downloaded in first iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ebcc79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ogbn-products dataset...\n",
      "Removing locked processed file: ../dataset\\ogbn_products\\processed\\data_processed\n",
      "  File is locked - trying to work around it...\n",
      "  Moved processed folder to backup\n",
      "Loading dataset with OGB...\n",
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/products.zip\n",
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/products.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 1.38 GB: 100%|██████████| 1414/1414 [02:39<00:00,  8.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset\\products.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "\n",
      "Dataset Statistics:\n",
      "  Nodes: 2,449,029\n",
      "  Edges: 123,718,280\n",
      "  Features: 100\n",
      "  Classes: 47\n",
      "  Train nodes: 196,615\n",
      "  Val nodes: 39,323\n",
      "  Test nodes: 2,213,091\n",
      "\n",
      "Dataset Statistics:\n",
      "  Nodes: 2,449,029\n",
      "  Edges: 123,718,280\n",
      "  Features: 100\n",
      "  Classes: 47\n",
      "  Train nodes: 196,615\n",
      "  Val nodes: 39,323\n",
      "  Test nodes: 2,213,091\n",
      "\n",
      "Cold-start nodes (degree ≤ 2): 236,775\n",
      "\n",
      "Cold-start nodes (degree ≤ 2): 236,775\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading ogbn-products dataset...\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "\n",
    "dataset_root = '../dataset'\n",
    "processed_file = os.path.join(dataset_root, 'ogbn_products', 'processed', 'data_processed')\n",
    "\n",
    "# Delete the locked processed file to force fresh processing\n",
    "if os.path.exists(processed_file):\n",
    "    try:\n",
    "        print(f\"Removing locked processed file: {processed_file}\")\n",
    "        os.remove(processed_file)\n",
    "        print(\"  File removed successfully\")\n",
    "    except PermissionError:\n",
    "        print(\"  File is locked - trying to work around it...\")\n",
    "        # Rename processed folder to bypass the lock\n",
    "        processed_dir = os.path.join(dataset_root, 'ogbn_products', 'processed')\n",
    "        backup_dir = os.path.join(dataset_root, 'ogbn_products', 'processed_backup')\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(backup_dir):\n",
    "                shutil.rmtree(backup_dir)\n",
    "            os.rename(processed_dir, backup_dir)\n",
    "            print(f\"  Moved processed folder to backup\")\n",
    "        except Exception as e2:\n",
    "            print(f\"  Could not rename: {e2}\")\n",
    "            print(\"  Trying alternative: loading with temporary directory...\")\n",
    "            \n",
    "            # Last resort: use completely separate temp directory\n",
    "            import tempfile\n",
    "            temp_root = tempfile.mkdtemp()\n",
    "            print(f\"  Using temporary directory: {temp_root}\")\n",
    "            dataset = NodePropPredDataset(name='ogbn-products', root=temp_root)\n",
    "            graph, labels_raw = dataset[0]\n",
    "            node_features = torch.tensor(graph['node_feat'], dtype=torch.float)\n",
    "            edge_index = torch.tensor(graph['edge_index'], dtype=torch.long)\n",
    "            labels = torch.tensor(labels_raw, dtype=torch.long).squeeze()\n",
    "            split_idx = dataset.get_idx_split()\n",
    "            \n",
    "            # Skip to the end\n",
    "            train_idx = torch.tensor(split_idx['train'], dtype=torch.long)\n",
    "            val_idx = torch.tensor(split_idx['valid'], dtype=torch.long)\n",
    "            test_idx = torch.tensor(split_idx['test'], dtype=torch.long)\n",
    "            \n",
    "            num_nodes = node_features.shape[0]\n",
    "            num_features = node_features.shape[1]\n",
    "            num_classes = len(torch.unique(labels))\n",
    "            \n",
    "            print(f\"\\nDataset Statistics:\")\n",
    "            print(f\"  Nodes: {num_nodes:,}\")\n",
    "            print(f\"  Edges: {edge_index.shape[1]:,}\")\n",
    "            print(f\"  Features: {num_features}\")\n",
    "            print(f\"  Classes: {num_classes}\")\n",
    "            print(f\"  Train nodes: {train_idx.shape[0]:,}\")\n",
    "            print(f\"  Val nodes: {val_idx.shape[0]:,}\")\n",
    "            print(f\"  Test nodes: {test_idx.shape[0]:,}\")\n",
    "            \n",
    "            degree = torch.bincount(edge_index[0])\n",
    "            cold_start_nodes = (degree <= 2).nonzero(as_tuple=True)[0]\n",
    "            print(f\"\\nCold-start nodes (degree ≤ 2): {len(cold_start_nodes):,}\")\n",
    "            \n",
    "            # Exit the cell here - we're done\n",
    "            raise SystemExit(0)\n",
    "\n",
    "# If we get here, the file was removed or renamed successfully\n",
    "print(\"Loading dataset with OGB...\")\n",
    "dataset = NodePropPredDataset(name='ogbn-products', root=dataset_root)\n",
    "graph, labels_raw = dataset[0]\n",
    "\n",
    "node_features = torch.tensor(graph['node_feat'], dtype=torch.float)\n",
    "edge_index = torch.tensor(graph['edge_index'], dtype=torch.long)\n",
    "labels = torch.tensor(labels_raw, dtype=torch.long).squeeze()\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "# Get splits\n",
    "train_idx = torch.tensor(split_idx['train'], dtype=torch.long)\n",
    "val_idx = torch.tensor(split_idx['valid'], dtype=torch.long)\n",
    "test_idx = torch.tensor(split_idx['test'], dtype=torch.long)\n",
    "\n",
    "# Dataset statistics\n",
    "num_nodes = node_features.shape[0]\n",
    "num_features = node_features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Nodes: {num_nodes:,}\")\n",
    "print(f\"  Edges: {edge_index.shape[1]:,}\")\n",
    "print(f\"  Features: {num_features}\")\n",
    "print(f\"  Classes: {num_classes}\")\n",
    "print(f\"  Train nodes: {train_idx.shape[0]:,}\")\n",
    "print(f\"  Val nodes: {val_idx.shape[0]:,}\")\n",
    "print(f\"  Test nodes: {test_idx.shape[0]:,}\")\n",
    "\n",
    "# Compute degree for cold-start analysis\n",
    "degree = torch.bincount(edge_index[0])\n",
    "cold_start_nodes = (degree <= 2).nonzero(as_tuple=True)[0]\n",
    "print(f\"\\nCold-start nodes (degree ≤ 2): {len(cold_start_nodes):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ab04d",
   "metadata": {},
   "source": [
    "## Build Adjacency List for Neighbor Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b2418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building adjacency list for neighbor sampling...\n",
      "Adjacency list created\n",
      "Adjacency list created\n"
     ]
    }
   ],
   "source": [
    "print(\"Building adjacency list for neighbor sampling...\")\n",
    "\n",
    "adj_list = {i: [] for i in range(num_nodes)}\n",
    "for src, dst in edge_index.t().numpy():\n",
    "    adj_list[src].append(dst)\n",
    "    adj_list[dst].append(src)  # undirected graph\n",
    "\n",
    "print(\"Adjacency list created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce7ef0",
   "metadata": {},
   "source": [
    "## Helper Functions for Neighbor Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f105e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor sampling functions defined\n"
     ]
    }
   ],
   "source": [
    "def sample_neighbors(nodes, adj_list, num_samples=[10, 5]):\n",
    "    \"\"\"Sample neighbors for multiple hops\"\"\"\n",
    "    all_nodes = set(nodes)\n",
    "    current_layer = set(nodes)\n",
    "    edges = []\n",
    "    \n",
    "    for k in num_samples:\n",
    "        next_layer = set()\n",
    "        for node in current_layer:\n",
    "            neighbors = adj_list.get(node, [])\n",
    "            if len(neighbors) > 0:\n",
    "                sampled = np.random.choice(\n",
    "                    neighbors, \n",
    "                    size=min(k, len(neighbors)), \n",
    "                    replace=False\n",
    "                )\n",
    "                for neighbor in sampled:\n",
    "                    edges.append((node, neighbor))\n",
    "                    next_layer.add(neighbor)\n",
    "                    all_nodes.add(neighbor)\n",
    "        current_layer = next_layer\n",
    "    \n",
    "    return list(all_nodes), edges\n",
    "\n",
    "\n",
    "def create_batches(node_indices, batch_size, adj_list, num_samples=[10, 5]):\n",
    "    \"\"\"Generate mini-batches with sampled neighborhoods\"\"\"\n",
    "    indices = node_indices.cpu().numpy()\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    batches = []\n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        batch_nodes = indices[i:i+batch_size]\n",
    "        sampled_nodes, sampled_edges = sample_neighbors(batch_nodes.tolist(), adj_list, num_samples)\n",
    "        batches.append((batch_nodes, sampled_nodes, sampled_edges))\n",
    "    \n",
    "    return batches\n",
    "\n",
    "print(\"Neighbor sampling functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37e623",
   "metadata": {},
   "source": [
    "## Model Architectures\n",
    "\n",
    "### 1. MLP Baseline (No Graph Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c153161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model defined\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron baseline - ignores graph structure\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.layers.append(nn.Linear(hidden_channels, out_channels))\n",
    "    \n",
    "    def forward(self, x, edge_index=None):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"MLP model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c00b84",
   "metadata": {},
   "source": [
    "### 2. GraphSAGE with Mean Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d55b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE model defined\n"
     ]
    }
   ],
   "source": [
    "class SAGEConvLayer(nn.Module):\n",
    "    \"\"\"GraphSAGE layer with mean aggregation\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2 * in_features, out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Mean aggregation\n",
    "        agg = torch.zeros(x.size(0), x.size(1), device=x.device)\n",
    "        deg = torch.zeros(x.size(0), device=x.device)\n",
    "        \n",
    "        agg.index_add_(0, row, x[col])\n",
    "        deg.index_add_(0, row, torch.ones(row.size(0), device=x.device))\n",
    "        \n",
    "        deg = deg.clamp(min=1).unsqueeze(1)\n",
    "        agg = agg / deg\n",
    "        \n",
    "        # Concatenate and transform\n",
    "        out = torch.cat([x, agg], dim=1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(SAGEConvLayer(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConvLayer(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConvLayer(hidden_channels, out_channels))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"GraphSAGE model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f816a",
   "metadata": {},
   "source": [
    "### 3. GraphSAGE with Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8b82b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE MaxPool model defined\n"
     ]
    }
   ],
   "source": [
    "class SAGEMaxPoolLayer(nn.Module):\n",
    "    \"\"\"GraphSAGE layer with max pooling aggregation\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(2 * in_features, out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Transform neighbor features\n",
    "        neighbor_feats = self.mlp(x)\n",
    "        \n",
    "        # Max pooling aggregation - avoid in-place operations\n",
    "        agg = torch.full((x.size(0), x.size(1)), float('-inf'), device=x.device)\n",
    "        \n",
    "        # Use scatter_reduce for max pooling (no in-place modification)\n",
    "        if edge_index.size(1) > 0:\n",
    "            agg = torch.scatter_reduce(\n",
    "                agg, 0, row.unsqueeze(1).expand(-1, x.size(1)), \n",
    "                neighbor_feats[col], reduce='amax', include_self=False\n",
    "            )\n",
    "        \n",
    "        # Replace -inf with 0 for nodes without neighbors\n",
    "        agg = torch.where(torch.isinf(agg), torch.zeros_like(agg), agg)\n",
    "        \n",
    "        # Concatenate and transform\n",
    "        out = torch.cat([x, agg], dim=1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GraphSAGEMaxPool(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(SAGEMaxPoolLayer(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEMaxPoolLayer(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEMaxPoolLayer(hidden_channels, out_channels))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"GraphSAGE MaxPool model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd364cd",
   "metadata": {},
   "source": [
    "### 4. Graph Convolutional Network (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c9848cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model defined\n"
     ]
    }
   ],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"Graph Convolutional Network layer\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Compute degree normalization\n",
    "        deg = torch.zeros(x.size(0), device=x.device)\n",
    "        deg.index_add_(0, row, torch.ones(row.size(0), device=x.device))\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "        # Normalize features\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Aggregate neighbors with normalization\n",
    "        out = torch.zeros_like(x)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        for i in range(edge_index.size(1)):\n",
    "            out[row[i]] += norm[i] * x[col[i]]\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(GCNLayer(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNLayer(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNLayer(hidden_channels, out_channels))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"GCN model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535fbc9",
   "metadata": {},
   "source": [
    "### 5. Graph Attention Network (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442d2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT model defined\n"
     ]
    }
   ],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    \"\"\"Graph Attention Network layer\"\"\"\n",
    "    def __init__(self, in_features, out_features, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.W = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Linear transformation\n",
    "        h = self.W(x)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        a_input = torch.cat([h[row], h[col]], dim=1)\n",
    "        e = F.leaky_relu(torch.matmul(a_input, self.a).squeeze(), negative_slope=0.2)\n",
    "        \n",
    "        # Compute attention coefficients\n",
    "        attention = torch.zeros(x.size(0), device=x.device)\n",
    "        attention.index_add_(0, row, torch.exp(e))\n",
    "        \n",
    "        alpha = torch.exp(e) / (attention[row] + 1e-16)\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Aggregate with attention\n",
    "        out = torch.zeros(x.size(0), self.out_features, device=x.device)\n",
    "        for i in range(edge_index.size(1)):\n",
    "            out[row[i]] += alpha[i] * h[col[i]]\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(GATLayer(in_channels, hidden_channels, dropout))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATLayer(hidden_channels, hidden_channels, dropout))\n",
    "        self.convs.append(GATLayer(hidden_channels, out_channels, dropout))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.elu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"GAT model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72818622",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c109ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch_mlp(model, train_idx, batch_size, node_feats, node_labels, optimizer, loss_fn, device):\n",
    "    \"\"\"Training function for MLP (no neighbor sampling needed)\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    indices = train_idx.cpu().numpy()\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_x = node_feats[batch_idx].to(device)\n",
    "        batch_y = node_labels[batch_idx].to(device)\n",
    "        \n",
    "        out = model(batch_x)\n",
    "        loss = loss_fn(out, batch_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(batch_idx)\n",
    "        total_examples += len(batch_idx)\n",
    "    \n",
    "    return total_loss / max(total_examples, 1)\n",
    "\n",
    "\n",
    "def train_epoch_gnn(model, train_idx, batch_size, adj_list, node_feats, node_labels, \n",
    "                    optimizer, loss_fn, device, num_samples=[10, 5]):\n",
    "    \"\"\"Training function for GNN models with neighbor sampling\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    batches = create_batches(train_idx, batch_size, adj_list, num_samples)\n",
    "    \n",
    "    for batch_target_nodes, sampled_nodes, sampled_edges in batches:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        node_map = {n: i for i, n in enumerate(sampled_nodes)}\n",
    "        batch_x = node_feats[sampled_nodes].to(device)\n",
    "        batch_y = node_labels[batch_target_nodes].to(device)\n",
    "        \n",
    "        # Create subgraph\n",
    "        subgraph_edges = []\n",
    "        for src, dst in sampled_edges:\n",
    "            if src in node_map and dst in node_map:\n",
    "                subgraph_edges.append([node_map[src], node_map[dst]])\n",
    "        \n",
    "        if len(subgraph_edges) > 0:\n",
    "            batch_edge_index = torch.tensor(subgraph_edges, dtype=torch.long).t().to(device)\n",
    "        else:\n",
    "            batch_edge_index = torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "        \n",
    "        out = model(batch_x, batch_edge_index)\n",
    "        target_indices = [node_map[n] for n in batch_target_nodes if n in node_map]\n",
    "        loss = loss_fn(out[target_indices], batch_y[:len(target_indices)])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(target_indices)\n",
    "        total_examples += len(target_indices)\n",
    "    \n",
    "    return total_loss / max(total_examples, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mlp(model, node_feats, node_labels, mask, device, batch_size=2048):\n",
    "    \"\"\"Evaluation for MLP\"\"\"\n",
    "    model.eval()\n",
    "    eval_indices = mask.nonzero(as_tuple=True)[0].numpy()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(0, len(eval_indices), batch_size):\n",
    "        batch_idx = eval_indices[i:i+batch_size]\n",
    "        batch_x = node_feats[batch_idx].to(device)\n",
    "        out = model(batch_x)\n",
    "        pred = out.argmax(dim=1).cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(node_labels[batch_idx])\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    acc = (all_preds == all_labels).sum().item() / len(all_labels)\n",
    "    return acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_gnn(model, node_feats, node_labels, mask, device, adj_list, \n",
    "                 batch_size=2048, num_samples=[10, 5]):\n",
    "    \"\"\"Evaluation for GNN models\"\"\"\n",
    "    model.eval()\n",
    "    eval_indices = mask.nonzero(as_tuple=True)[0].numpy()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(0, len(eval_indices), batch_size):\n",
    "        batch_target_nodes = eval_indices[i:i+batch_size]\n",
    "        sampled_nodes, sampled_edges = sample_neighbors(batch_target_nodes.tolist(), adj_list, num_samples)\n",
    "        node_map = {n: idx for idx, n in enumerate(sampled_nodes)}\n",
    "        \n",
    "        batch_x = node_feats[sampled_nodes].to(device)\n",
    "        \n",
    "        subgraph_edges = []\n",
    "        for src, dst in sampled_edges:\n",
    "            if src in node_map and dst in node_map:\n",
    "                subgraph_edges.append([node_map[src], node_map[dst]])\n",
    "        \n",
    "        if len(subgraph_edges) > 0:\n",
    "            batch_edge_index = torch.tensor(subgraph_edges, dtype=torch.long).t().to(device)\n",
    "        else:\n",
    "            batch_edge_index = torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "        \n",
    "        out = model(batch_x, batch_edge_index)\n",
    "        target_indices = [node_map[n] for n in batch_target_nodes if n in node_map]\n",
    "        pred = out[target_indices].argmax(dim=1).cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(node_labels[batch_target_nodes[:len(target_indices)]])\n",
    "        \n",
    "        del out, batch_x, batch_edge_index\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    acc = (all_preds == all_labels).sum().item() / len(all_labels)\n",
    "    return acc\n",
    "\n",
    "print(\"Training and evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42a7ef",
   "metadata": {},
   "source": [
    "## Model Training Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c975edeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training wrapper defined\n"
     ]
    }
   ],
   "source": [
    "def train_model(model_name, model, is_gnn=True, epochs=10, batch_size=1024, lr=0.001):\n",
    "    \"\"\"Train a model and track performance\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    train_mask[train_idx.cpu()] = True\n",
    "    val_mask[val_idx.cpu()] = True\n",
    "    test_mask[test_idx.cpu()] = True\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_acc': [],\n",
    "        'test_acc': [],\n",
    "        'epoch_time': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        if is_gnn:\n",
    "            loss = train_epoch_gnn(model, train_idx, batch_size, adj_list, \n",
    "                                   node_features.cpu(), labels.cpu(), \n",
    "                                   optimizer, loss_fn, device)\n",
    "        else:\n",
    "            loss = train_epoch_mlp(model, train_idx, batch_size, \n",
    "                                   node_features.cpu(), labels.cpu(), \n",
    "                                   optimizer, loss_fn, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        if is_gnn:\n",
    "            val_acc = evaluate_gnn(model, node_features.cpu(), labels.cpu(), \n",
    "                                   val_mask, device, adj_list)\n",
    "            test_acc = evaluate_gnn(model, node_features.cpu(), labels.cpu(), \n",
    "                                    test_mask, device, adj_list)\n",
    "        else:\n",
    "            val_acc = evaluate_mlp(model, node_features.cpu(), labels.cpu(), \n",
    "                                   val_mask, device)\n",
    "            test_acc = evaluate_mlp(model, node_features.cpu(), labels.cpu(), \n",
    "                                    test_mask, device)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        history['train_loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['epoch_time'].append(epoch_time)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | Loss: {loss:.4f} | \"\n",
    "              f\"Val: {val_acc:.4f} | Test: {test_acc:.4f} | Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Test accuracy at best val: {best_test_acc:.4f}\")\n",
    "    \n",
    "    return history, best_val_acc, best_test_acc\n",
    "\n",
    "print(\"Training wrapper defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862eaf14",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80471855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model comparison...\n",
      "\n",
      "Configuration:\n",
      "  Hidden dimension: 256\n",
      "  Number of layers: 2\n",
      "  Dropout: 0.5\n",
      "  Epochs: 10\n",
      "  Batch size: 1024\n",
      "  Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "LR = 0.001\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Starting model comparison...\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Hidden dimension: {HIDDEN_DIM}\")\n",
    "print(f\"  Number of layers: {NUM_LAYERS}\")\n",
    "print(f\"  Dropout: {DROPOUT}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33163cb",
   "metadata": {},
   "source": [
    "## Train All Models\n",
    "\n",
    "### 1. MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8034b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training MLP Baseline\n",
      "============================================================\n",
      "Parameters: 37,935\n",
      "Epoch  1/10 | Loss: 1.9699 | Val: 0.6104 | Test: 0.4880 | Time: 1.4s\n",
      "Epoch  1/10 | Loss: 1.9699 | Val: 0.6104 | Test: 0.4880 | Time: 1.4s\n",
      "Epoch  2/10 | Loss: 1.3672 | Val: 0.6481 | Test: 0.5219 | Time: 1.2s\n",
      "Epoch  2/10 | Loss: 1.3672 | Val: 0.6481 | Test: 0.5219 | Time: 1.2s\n",
      "Epoch  3/10 | Loss: 1.2801 | Val: 0.6632 | Test: 0.5350 | Time: 1.2s\n",
      "Epoch  3/10 | Loss: 1.2801 | Val: 0.6632 | Test: 0.5350 | Time: 1.2s\n",
      "Epoch  4/10 | Loss: 1.2325 | Val: 0.6759 | Test: 0.5464 | Time: 1.2s\n",
      "Epoch  4/10 | Loss: 1.2325 | Val: 0.6759 | Test: 0.5464 | Time: 1.2s\n",
      "Epoch  5/10 | Loss: 1.2021 | Val: 0.6811 | Test: 0.5489 | Time: 1.2s\n",
      "Epoch  5/10 | Loss: 1.2021 | Val: 0.6811 | Test: 0.5489 | Time: 1.2s\n",
      "Epoch  6/10 | Loss: 1.1780 | Val: 0.6935 | Test: 0.5590 | Time: 1.2s\n",
      "Epoch  6/10 | Loss: 1.1780 | Val: 0.6935 | Test: 0.5590 | Time: 1.2s\n",
      "Epoch  7/10 | Loss: 1.1632 | Val: 0.6964 | Test: 0.5613 | Time: 1.2s\n",
      "Epoch  7/10 | Loss: 1.1632 | Val: 0.6964 | Test: 0.5613 | Time: 1.2s\n",
      "Epoch  8/10 | Loss: 1.1460 | Val: 0.7012 | Test: 0.5669 | Time: 1.2s\n",
      "Epoch  8/10 | Loss: 1.1460 | Val: 0.7012 | Test: 0.5669 | Time: 1.2s\n",
      "Epoch  9/10 | Loss: 1.1389 | Val: 0.7040 | Test: 0.5667 | Time: 1.2s\n",
      "Epoch  9/10 | Loss: 1.1389 | Val: 0.7040 | Test: 0.5667 | Time: 1.2s\n",
      "Epoch 10/10 | Loss: 1.1279 | Val: 0.7058 | Test: 0.5692 | Time: 1.2s\n",
      "\n",
      "Best validation accuracy: 0.7058\n",
      "Test accuracy at best val: 0.5692\n",
      "Epoch 10/10 | Loss: 1.1279 | Val: 0.7058 | Test: 0.5692 | Time: 1.2s\n",
      "\n",
      "Best validation accuracy: 0.7058\n",
      "Test accuracy at best val: 0.5692\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
    "mlp_history, mlp_val, mlp_test = train_model(\n",
    "    \"MLP Baseline\", mlp_model, is_gnn=False, \n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR\n",
    ")\n",
    "results['MLP'] = {'history': mlp_history, 'val_acc': mlp_val, 'test_acc': mlp_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8228b40",
   "metadata": {},
   "source": [
    "### 2. GraphSAGE (Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b406c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training GraphSAGE (Mean)\n",
      "============================================================\n",
      "Parameters: 75,567\n",
      "Epoch  1/10 | Loss: 1.0972 | Val: 0.8475 | Test: 0.6846 | Time: 2399.1s\n",
      "Epoch  1/10 | Loss: 1.0972 | Val: 0.8475 | Test: 0.6846 | Time: 2399.1s\n",
      "Epoch  2/10 | Loss: 0.5454 | Val: 0.8646 | Test: 0.7046 | Time: 2478.0s\n",
      "Epoch  2/10 | Loss: 0.5454 | Val: 0.8646 | Test: 0.7046 | Time: 2478.0s\n",
      "Epoch  3/10 | Loss: 0.4858 | Val: 0.8742 | Test: 0.7128 | Time: 2579.8s\n",
      "Epoch  3/10 | Loss: 0.4858 | Val: 0.8742 | Test: 0.7128 | Time: 2579.8s\n",
      "Epoch  4/10 | Loss: 0.4560 | Val: 0.8784 | Test: 0.7223 | Time: 2561.9s\n",
      "Epoch  4/10 | Loss: 0.4560 | Val: 0.8784 | Test: 0.7223 | Time: 2561.9s\n",
      "Epoch  5/10 | Loss: 0.4381 | Val: 0.8827 | Test: 0.7318 | Time: 2559.8s\n",
      "Epoch  5/10 | Loss: 0.4381 | Val: 0.8827 | Test: 0.7318 | Time: 2559.8s\n",
      "Epoch  6/10 | Loss: 0.4227 | Val: 0.8847 | Test: 0.7362 | Time: 2557.4s\n",
      "Epoch  6/10 | Loss: 0.4227 | Val: 0.8847 | Test: 0.7362 | Time: 2557.4s\n",
      "Epoch  7/10 | Loss: 0.4165 | Val: 0.8880 | Test: 0.7429 | Time: 2424.0s\n",
      "Epoch  7/10 | Loss: 0.4165 | Val: 0.8880 | Test: 0.7429 | Time: 2424.0s\n",
      "Epoch  8/10 | Loss: 0.4046 | Val: 0.8900 | Test: 0.7468 | Time: 2365.8s\n",
      "Epoch  8/10 | Loss: 0.4046 | Val: 0.8900 | Test: 0.7468 | Time: 2365.8s\n",
      "Epoch  9/10 | Loss: 0.3995 | Val: 0.8926 | Test: 0.7483 | Time: 2315.4s\n",
      "Epoch  9/10 | Loss: 0.3995 | Val: 0.8926 | Test: 0.7483 | Time: 2315.4s\n",
      "Epoch 10/10 | Loss: 0.3913 | Val: 0.8931 | Test: 0.7528 | Time: 2355.2s\n",
      "\n",
      "Best validation accuracy: 0.8931\n",
      "Test accuracy at best val: 0.7528\n",
      "Epoch 10/10 | Loss: 0.3913 | Val: 0.8931 | Test: 0.7528 | Time: 2355.2s\n",
      "\n",
      "Best validation accuracy: 0.8931\n",
      "Test accuracy at best val: 0.7528\n"
     ]
    }
   ],
   "source": [
    "sage_model = GraphSAGE(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
    "sage_history, sage_val, sage_test = train_model(\n",
    "    \"GraphSAGE (Mean)\", sage_model, is_gnn=True, \n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR\n",
    ")\n",
    "results['GraphSAGE-Mean'] = {'history': sage_history, 'val_acc': sage_val, 'test_acc': sage_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fcec6",
   "metadata": {},
   "source": [
    "### 3. GraphSAGE (MaxPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e858486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training GraphSAGE (MaxPool)\n",
      "============================================================\n",
      "Parameters: 151,459\n",
      "Epoch  1/10 | Loss: 1.1030 | Val: 0.8304 | Test: 0.6747 | Time: 2379.4s\n",
      "Epoch  1/10 | Loss: 1.1030 | Val: 0.8304 | Test: 0.6747 | Time: 2379.4s\n",
      "Epoch  2/10 | Loss: 0.5914 | Val: 0.8549 | Test: 0.6955 | Time: 2379.4s\n",
      "Epoch  2/10 | Loss: 0.5914 | Val: 0.8549 | Test: 0.6955 | Time: 2379.4s\n",
      "Epoch  3/10 | Loss: 0.5128 | Val: 0.8675 | Test: 0.7161 | Time: 2376.2s\n",
      "Epoch  3/10 | Loss: 0.5128 | Val: 0.8675 | Test: 0.7161 | Time: 2376.2s\n",
      "Epoch  4/10 | Loss: 0.4727 | Val: 0.8749 | Test: 0.7208 | Time: 2377.8s\n",
      "Epoch  4/10 | Loss: 0.4727 | Val: 0.8749 | Test: 0.7208 | Time: 2377.8s\n",
      "Epoch  5/10 | Loss: 0.4415 | Val: 0.8819 | Test: 0.7321 | Time: 2377.3s\n",
      "Epoch  5/10 | Loss: 0.4415 | Val: 0.8819 | Test: 0.7321 | Time: 2377.3s\n",
      "Epoch  6/10 | Loss: 0.4252 | Val: 0.8808 | Test: 0.7364 | Time: 2367.5s\n",
      "Epoch  6/10 | Loss: 0.4252 | Val: 0.8808 | Test: 0.7364 | Time: 2367.5s\n",
      "Epoch  7/10 | Loss: 0.4149 | Val: 0.8898 | Test: 0.7390 | Time: 2374.9s\n",
      "Epoch  7/10 | Loss: 0.4149 | Val: 0.8898 | Test: 0.7390 | Time: 2374.9s\n",
      "Epoch  8/10 | Loss: 0.4011 | Val: 0.8880 | Test: 0.7387 | Time: 2358.5s\n",
      "Epoch  8/10 | Loss: 0.4011 | Val: 0.8880 | Test: 0.7387 | Time: 2358.5s\n",
      "Epoch  9/10 | Loss: 0.3978 | Val: 0.8888 | Test: 0.7415 | Time: 2355.3s\n",
      "Epoch  9/10 | Loss: 0.3978 | Val: 0.8888 | Test: 0.7415 | Time: 2355.3s\n",
      "Epoch 10/10 | Loss: 0.3898 | Val: 0.8891 | Test: 0.7460 | Time: 2345.9s\n",
      "\n",
      "Best validation accuracy: 0.8898\n",
      "Test accuracy at best val: 0.7390\n",
      "Epoch 10/10 | Loss: 0.3898 | Val: 0.8891 | Test: 0.7460 | Time: 2345.9s\n",
      "\n",
      "Best validation accuracy: 0.8898\n",
      "Test accuracy at best val: 0.7390\n"
     ]
    }
   ],
   "source": [
    "sage_max_model = GraphSAGEMaxPool(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
    "sage_max_history, sage_max_val, sage_max_test = train_model(\n",
    "    \"GraphSAGE (MaxPool)\", sage_max_model, is_gnn=True, \n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR\n",
    ")\n",
    "results['GraphSAGE-MaxPool'] = {'history': sage_max_history, 'val_acc': sage_max_val, 'test_acc': sage_max_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a9c1f",
   "metadata": {},
   "source": [
    "### 4. GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8e76ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training GCN\n",
      "============================================================\n",
      "Parameters: 37,935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gcn_model \u001b[38;5;241m=\u001b[39m GCN(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m gcn_history, gcn_val, gcn_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGCN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgcn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_gnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGCN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: gcn_history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: gcn_val, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: gcn_test}\n",
      "Cell \u001b[1;32mIn[27], line 34\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_name, model, is_gnn, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_gnn:\n\u001b[1;32m---> 34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_epoch_mlp(model, train_idx, batch_size, \n\u001b[0;32m     39\u001b[0m                            node_features\u001b[38;5;241m.\u001b[39mcpu(), labels\u001b[38;5;241m.\u001b[39mcpu(), \n\u001b[0;32m     40\u001b[0m                            optimizer, loss_fn, device)\n",
      "Cell \u001b[1;32mIn[26], line 56\u001b[0m, in \u001b[0;36mtrain_epoch_gnn\u001b[1;34m(model, train_idx, batch_size, adj_list, node_feats, node_labels, optimizer, loss_fn, device, num_samples)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     batch_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 56\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m target_indices \u001b[38;5;241m=\u001b[39m [node_map[n] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m batch_target_nodes \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m node_map]\n\u001b[0;32m     58\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out[target_indices], batch_y[:\u001b[38;5;28mlen\u001b[39m(target_indices)])\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 43\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs):\n\u001b[1;32m---> 43\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     45\u001b[0m             x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 24\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     21\u001b[0m norm \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[row] \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[col]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m---> 24\u001b[0m     out[row[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m norm[i] \u001b[38;5;241m*\u001b[39m x[col[i]]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
    "gcn_history, gcn_val, gcn_test = train_model(\n",
    "    \"GCN\", gcn_model, is_gnn=True, \n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR\n",
    ")\n",
    "results['GCN'] = {'history': gcn_history, 'val_acc': gcn_val, 'test_acc': gcn_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036ff2a",
   "metadata": {},
   "source": [
    "### 5. GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training GAT\n",
      "============================================================\n",
      "Parameters: 38,238\n",
      "Epoch  1/10 | Loss: nan | Val: 0.0583 | Test: 0.0455 | Time: 72562.3s\n",
      "Epoch  1/10 | Loss: nan | Val: 0.0583 | Test: 0.0455 | Time: 72562.3s\n"
     ]
    }
   ],
   "source": [
    "gat_model = GAT(num_features, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
    "gat_history, gat_val, gat_test = train_model(\n",
    "    \"GAT\", gat_model, is_gnn=True, \n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR\n",
    ")\n",
    "results['GAT'] = {'history': gat_history, 'val_acc': gat_val, 'test_acc': gat_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fb9ad",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "for model_name, data in results.items():\n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Best Val Acc': data['val_acc'],\n",
    "        'Test Acc': data['test_acc'],\n",
    "        'Avg Epoch Time (s)': np.mean(data['history']['epoch_time']),\n",
    "        'Final Train Loss': data['history']['train_loss'][-1]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Test Acc', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Find best model\n",
    "best_model = summary_df.iloc[0]\n",
    "print(f\"🏆 Best Model: {best_model['Model']}\")\n",
    "print(f\"   Test Accuracy: {best_model['Test Acc']:.4f}\")\n",
    "print(f\"   Validation Accuracy: {best_model['Best Val Acc']:.4f}\")\n",
    "print(f\"   Avg Training Time: {best_model['Avg Epoch Time (s)']:.2f}s per epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8611b9",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Test Accuracy Comparison\n",
    "ax1 = axes[0, 0]\n",
    "models = summary_df['Model'].values\n",
    "test_accs = summary_df['Test Acc'].values\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
    "ax1.barh(models, test_accs, color=colors)\n",
    "ax1.set_xlabel('Test Accuracy')\n",
    "ax1.set_title('Test Accuracy by Model')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: Training Loss Curves\n",
    "ax2 = axes[0, 1]\n",
    "for model_name, data in results.items():\n",
    "    ax2.plot(data['history']['train_loss'], label=model_name, marker='o')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Training Loss')\n",
    "ax2.set_title('Training Loss Over Time')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Validation Accuracy Curves\n",
    "ax3 = axes[1, 0]\n",
    "for model_name, data in results.items():\n",
    "    ax3.plot(data['history']['val_acc'], label=model_name, marker='o')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Validation Accuracy')\n",
    "ax3.set_title('Validation Accuracy Over Time')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Accuracy vs Speed Trade-off\n",
    "ax4 = axes[1, 1]\n",
    "times = summary_df['Avg Epoch Time (s)'].values\n",
    "accs = summary_df['Test Acc'].values\n",
    "ax4.scatter(times, accs, s=200, alpha=0.6, c=range(len(models)), cmap='viridis')\n",
    "for i, model in enumerate(models):\n",
    "    ax4.annotate(model, (times[i], accs[i]), fontsize=9, alpha=0.8)\n",
    "ax4.set_xlabel('Avg Training Time per Epoch (s)')\n",
    "ax4.set_ylabel('Test Accuracy')\n",
    "ax4.set_title('Accuracy vs Training Speed')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete! Saved to model_comparison_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68abb81",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to CSV\n",
    "summary_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"Results saved to model_comparison_results.csv\")\n",
    "\n",
    "# Save best model\n",
    "best_model_name = summary_df.iloc[0]['Model']\n",
    "print(f\"\\nBest model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de38f4d",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d873f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Improvement over baseline\n",
    "mlp_acc = summary_df[summary_df['Model'] == 'MLP']['Test Acc'].values[0]\n",
    "print(f\"\\nMLP Baseline Accuracy: {mlp_acc:.4f}\")\n",
    "print(\"\\nImprovement over MLP baseline:\")\n",
    "for _, row in summary_df.iterrows():\n",
    "    if row['Model'] != 'MLP':\n",
    "        improvement = (row['Test Acc'] - mlp_acc) * 100\n",
    "        print(f\"  {row['Model']:20s}: +{improvement:.2f}% ({row['Test Acc']:.4f})\")\n",
    "\n",
    "# Speed comparison\n",
    "print(\"\\nTraining Speed:\")\n",
    "for _, row in summary_df.iterrows():\n",
    "    print(f\"  {row['Model']:20s}: {row['Avg Epoch Time (s)']:.2f}s per epoch\")\n",
    "\n",
    "# Convergence analysis\n",
    "print(\"\\nConvergence (epochs to reach 90% of final val accuracy):\")\n",
    "for model_name, data in results.items():\n",
    "    final_val = data['val_acc']\n",
    "    target = 0.9 * final_val\n",
    "    val_history = data['history']['val_acc']\n",
    "    epochs_to_converge = next((i+1 for i, v in enumerate(val_history) if v >= target), len(val_history))\n",
    "    print(f\"  {model_name:20s}: {epochs_to_converge} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b3d17",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee152561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best = summary_df.iloc[0]\n",
    "fastest = summary_df.loc[summary_df['Avg Epoch Time (s)'].idxmin()]\n",
    "\n",
    "print(f\"\\n✅ For best accuracy: Use {best['Model']}\")\n",
    "print(f\"   - Test Accuracy: {best['Test Acc']:.4f}\")\n",
    "print(f\"   - Training time: {best['Avg Epoch Time (s)']:.2f}s/epoch\")\n",
    "\n",
    "print(f\"\\n⚡ For fastest training: Use {fastest['Model']}\")\n",
    "print(f\"   - Test Accuracy: {fastest['Test Acc']:.4f}\")\n",
    "print(f\"   - Training time: {fastest['Avg Epoch Time (s)']:.2f}s/epoch\")\n",
    "\n",
    "print(\"\\n📊 Key Findings:\")\n",
    "print(f\"   - Graph structure provides {((best['Test Acc'] - mlp_acc) / mlp_acc * 100):.1f}% improvement\")\n",
    "print(f\"   - {best['Model']} achieves the best performance\")\n",
    "print(f\"   - All GNN models outperform the MLP baseline\")\n",
    "\n",
    "print(\"\\n🔬 Next Steps:\")\n",
    "print(\"   1. Fine-tune hyperparameters for the best model\")\n",
    "print(\"   2. Try different neighbor sampling strategies\")\n",
    "print(\"   3. Analyze cold-start node performance specifically\")\n",
    "print(\"   4. Consider ensemble methods combining multiple models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
